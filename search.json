[
  {
    "objectID": "pages/320-built-in-functions.html",
    "href": "pages/320-built-in-functions.html",
    "title": "Built-in functions",
    "section": "",
    "text": "Operators\nThroughout the course today we have written several function which perform simple tasks such as:\n\ndef add(x, y):\n    \"\"\"Function to return the sum of the two arguments\"\"\"\n    return x + y\n\ndef product(x, y):\n    \"\"\"Function to return the product of the two arguments\"\"\"\n    return x * y\n\ndef square(x):\n    \"\"\"Function to return the square of the argument\"\"\"\n    return x * x\n\nWe had to do this since functional programming requires the passing of the names of real functions. We can’t for example do:\nmap(*, a, b)\nand expect it to multiply together the lists’ elements. In our case we instead had to pass in our defined function product which takes two arguments:\nmap(product, a, b)\nSince using mathematical operations in a functional context is very common in Python, it already provides functions which implement the operators in a module called operator:\n\nimport operator\n\noperator.mul(5, 7)\n\n35\n\n\nwhich means that we can use them in our maps, ProcessPoolExecutor.maps and reduces:\n\na = [1, 2, 3]\nb = [4, 5, 6]\n\nlist(map(operator.mul, a, b))\n\n[4, 10, 18]\n\n\n\nlist(map(operator.pow, a, b))\n\n[1, 32, 729]\n\n\nThese functions can be used in reductions too:\n\nfrom functools import reduce\n\nreduce(operator.mul, [1, 2, 3, 4])\n\n24\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTake the answer to the first exercise in the Parallel map/reduce where we created countlines.py (solution here) and rewrite the line\ntotal = reduce(lambda x, y: x + y, play_line_count)\nto use the correct function from the operator module.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\ncountlines.py\n\nimport glob\nimport sys\nimport operator\n\nfrom functools import reduce\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\nif __name__ == \"__main__\":\n    # get all of the names of the plays from the command line\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        # map the count_lines function against all of the\n        # files listed in \"filenames\"\n        play_line_count = pool.map(count_lines_in_file, files)\n        \n        # convert it to a list as we need to use the result in two places.\n        play_line_count = list(play_line_count)\n\n        for f, count in zip(files, play_line_count):\n            print(f\"{f} has {count} lines\")\n\n    total = reduce(operator.add, play_line_count)\n    print(f\"The total number of lines is {total}.\")\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines\nThe total number of lines is 119713.\n\n\n\n\n\nReductions\nAnother common thing we did with our results was to reduce them down to a single value by adding them together. We did this with:\n\nreduce(lambda x, y: x + y, [1, 2, 3, 4])\n\n10\n\n\nThis is such a common thing to do that Python has a built-in function to add together all the numbers in a sequence, sum:\n\nsum([1, 2, 3, 4])\n\n10\n\n\nThe documentation for this function is at built-in functions and there are a few other reduction functions such as min, max, any and all. Most reduction functions are simple and there’s nothing wrong with writing your own but if there’s already one provided by Python then it’s probably worth using it.\n\n\n\n\n\n\nExercise\n\n\n\nEdit countlines.py again to use the sum function in-place of the custom reduction.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\ncountlines.py\n\nimport glob\nimport sys\n\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\nif __name__ == \"__main__\":\n    # get all of the names of the plays from the command line\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        # map the count_lines function against all of the\n        # files listed in \"filenames\"\n        play_line_count = pool.map(count_lines_in_file, files)\n        \n        # convert it to a list as we need to use the result in two places.\n        play_line_count = list(play_line_count)\n\n        for f, count in zip(files, play_line_count):\n            print(f\"{f} has {count} lines\")\n\n    total = sum(play_line_count)\n    print(f\"The total number of lines is {total}.\")\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines\nThe total number of lines is 119713.\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUsing a reduction function from the statistics module, edit countlines.py to also print the average of the number of lines per file at the end of the program.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\ncountlines.py\n\nimport glob\nimport sys\nimport statistics\n\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\nif __name__ == \"__main__\":\n    # get all of the names of the plays from the command line\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        # map the count_lines function against all of the\n        # files listed in \"filenames\"\n        play_line_count = pool.map(count_lines_in_file, files)\n        \n        # convert it to a list as we need to use the result in two places.\n        play_line_count = list(play_line_count)\n\n        for f, count in zip(files, play_line_count):\n            print(f\"{f} has {count} lines\")\n\n    total = sum(play_line_count)\n    print(f\"The total number of lines is {total}.\")\n\n    average = statistics.mean(play_line_count)  # This is a new line\n    print(f\"The average number of lines is {int(average)}.\")  # This is a new line\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines\nThe total number of lines is 119713.\nThe average number of lines is 4275.",
    "crumbs": [
      "Multi-node (distributed/cluster) Parallel Programming",
      "Built-in functions"
    ]
  },
  {
    "objectID": "pages/001-workspace-setup.html",
    "href": "pages/001-workspace-setup.html",
    "title": "Workspace setup",
    "section": "",
    "text": "For the purpose of this course we recommend using a free tool called JupyterLab which provides you with a local editor in your web browser where you can write and run Python code. The easiest way to get access to JupyterLab is to install Anaconda which is a piece of software which includes Python along with lots of other tools. It is freely available for Windows, MacOS and Linux.\nAnaconda can be installed into your home area on your computer so if you are on a work laptop, for example, you will not need any special permissions. Once Anaconda is installed, start “Anaconda Navigator” and press the JupyterLab button on the main screen:\n\nThis will open JupyterLab in your default web browser and will look something like this:\n\nThe way that we will be setting up the space is to have a text editor on the left-hand side of the screen and a terminal on the right hand side. We’ll use the editor to write our code and the terminal to run it.\nIn the launcher tab, scoll down to the “Text File” entry and click that. It will turn the editor into a text editor. Then go to File → New and select “Terminal”. It will now have two tabs inside the interface, one labelled “untitled.txt” and the other labelled “Terminal 1”:\n\nThe contents of the Terminal tab will likely be a little different on your computer, compared to what is shown in thise images but that is ok.\nTo make our lives easier, let’s rearange things so that we can see the text editor at the same time as the terminal. Do this by pressing and holding down the left mouse button on the tab that says “Terminal 1” and slowly dragging it to the right-hand side of the window. You’ll see a blue outline like this:\n\nRelease the mouse button and you’ll end up with the two showing side-by-side:\n\n\nWorking directory\nSetting the correct working directory helps organize your project files and ensures that your code can find necessary resources and dependencies. We will revisit this concept later on, but for now be mindful that the space where you save your scripts has to be the same than the working directory in your Command Prompt/Terminal.\nIf you are using the Command Prompt (Windows) you can check your current directory with\n\n\nCommand Prompt\n\ncd\n\nIf you are using a Terminal (MacOS and Linux) you can check your current directory with\n\n\nTerminal\n\npwd\n\nWe’re now ready to get started!",
    "crumbs": [
      "Workspace setup"
    ]
  },
  {
    "objectID": "pages/answer_shakespeare_multi.html",
    "href": "pages/answer_shakespeare_multi.html",
    "title": "Introducing Parallel Python",
    "section": "",
    "text": "countlines.py\n\nimport glob\nimport sys\n  \nfrom functools import reduce\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\nif __name__ == \"__main__\":\n    # get all of the names of the plays from the command line\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        # map the count_lines function against all of the\n        # files listed in \"filenames\"\n        play_line_count = pool.map(count_lines_in_file, files)\n        \n        # convert it to a list as we need to use the result in two places.\n        play_line_count = list(play_line_count)\n\n        for f, count in zip(files, play_line_count):\n            print(f\"{f} has {count} lines\")\n\n    total = reduce(lambda x, y: x + y, play_line_count)\n    print(f\"The total number of lines is {total}.\")\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines\nThe total number of lines is 119713."
  },
  {
    "objectID": "pages/300-multi-node-parallel-programming.html",
    "href": "pages/300-multi-node-parallel-programming.html",
    "title": "Multi-node (distributed/cluster) Parallel Programming",
    "section": "",
    "text": "Python comes with built-in support for parallelising scripts locally over the compute cores of a single computer. However, as yet, there is no in-built support for parallelising scripts over the nodes of a cluster, e.g. distributed parallel programming.\nFortunately, there are several third party libraries that are beginning to appear that support distributed clusters, e.g. MPI4Py, IPython Parallel, Dask and Parallel Python. Most of these are based on the concepts of mapping, asynchronous functions, futures, and functional programming, so you should find that the concepts you have learned in parts 1 and 2 will be useful as you explore the developing ecosystem of distributed parallel Python libraries.\nIn this part, we will take a quick look at one such library, called MPI4Py.\n\nMPI4Py\nMPI4Py is an actively developed third-party Python module that supports running parallel Python scripts across clouds, distributed compute clusters, HPC machines etc.\nIf you are running Python on your own computer, then you can install MPI4Py using either: - pip install mpi4py if you have installed pip - conda install -c anaconda mpi4py if you are using Anaconda Python or use the Environments tab in Anaconda Navigator.\nNote that in order to install this library though pip, you will need to install the MPI libraries as well. Anaconda can install them for you automatically.\nFor more information regarding installing the library on your own computer, see the official documentation.\nIf you are using Python installed on a cluster, then MPI4Py should already have been installed for you (if not, email your cluster systems administrator).",
    "crumbs": [
      "Multi-node (distributed/cluster) Parallel Programming"
    ]
  },
  {
    "objectID": "pages/250-asynchronous-mapping.html",
    "href": "pages/250-asynchronous-mapping.html",
    "title": "Asynchronous Mapping",
    "section": "",
    "text": "Asynchronous functions allow you to give different tasks to different members of the process pool. However, giving functions one by one is not very efficient. It would be good to be able to combine mapping with asynchronous functions, i.e. be able to give different mapping tasks simultanously to the pool of workers.\nCreate a new python script called asyncmap.py and copy into it\n\n\nasyncmap.py\n\nimport os\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\nfrom functools import reduce\n\ndef add(x, y):\n    \"\"\"Return the sum of the arguments\"\"\"\n    print(f\"Worker {os.getpid()} is processing add({x}, {y})\")\n    time.sleep(1)\n    return x + y\n\ndef product(x, y):\n    \"\"\"Return the product of the arguments\"\"\"\n    print(f\"Worker {os.getpid()} is processing product({x}, {y})\")\n    time.sleep(1)\n    return x * y\n\nif __name__ == \"__main__\":\n\n    a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n    b = [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n\n    # Now create a Pool of workers\n    with ProcessPoolExecutor() as pool:\n        sum_results = pool.map(add, a, b)\n        product_results = pool.map(product, a, b)\n        print(\"All the jobs are submitted, now we wait for results...\")\n\n    total_sum = reduce(lambda x, y: x + y, sum_results)\n    total_product = reduce(lambda x, y: x + y, product_results)\n\n    print(f\"Sum of sums of 'a' and 'b' is {total_sum}\")\n    print(f\"Sum of products of 'a' and 'b' is {total_product}\")\n\nOverwriting asyncmap.py\nRunning this script using should give output similar to:\npython asyncmap.py\nAll the jobs are submitted, now we wait for results...\nWorker 8739 is processing add(1, 11)\nWorker 8740 is processing add(2, 12)\nWorker 8742 is processing add(4, 14)\nWorker 8741 is processing add(3, 13)\nWorker 8739 is processing add(5, 15)\nWorker 8742 is processing add(6, 16)\nWorker 8740 is processing add(7, 17)\nWorker 8741 is processing add(8, 18)\nWorker 8739 is processing add(9, 19)\nWorker 8742 is processing add(10, 20)\nWorker 8740 is processing product(1, 11)\nWorker 8741 is processing product(2, 12)\nWorker 8742 is processing product(3, 13)\nWorker 8741 is processing product(4, 14)\nWorker 8739 is processing product(5, 15)\nWorker 8740 is processing product(6, 16)\nWorker 8742 is processing product(7, 17)\nWorker 8739 is processing product(8, 18)\nWorker 8741 is processing product(9, 19)\nWorker 8740 is processing product(10, 20)\nSum of sums of 'a' and 'b' is 210\nSum of products of 'a' and 'b' is 935\nThis script provides two functions, add and product, which are mapped using the ProcessPoolExecutor.map function. We didn’t mention it before but the map is performed asynchronously, just like the submit function was. The map function does not return an explicit Future object though, instead the results will be automatically waited-for as you loop through the result (in this case they are looped-through implicitly by the reduce).\n\nChunking\nBy default, the ProcessPoolExecutor.map function divides the work over the pool of workers by assigning pieces of work one-by-one. In the example above, the work to be performed was:\nadd(1, 11)\nadd(2, 12)\nadd(3, 13)\n...\nadd(10,20)\nproduct(1, 11)\nproduct(2, 12)\nproduct(3, 13)\n...\nproduct(10, 20)\nThe work was assigned one by one to the four workers on my computer, i.e. the first worker process was given add(1, 11), the second add(2, 12), the third add(3, 13) the then the fourth add(4, 14). The first worker to finish was then given add(5, 15), then the next given add(6, 16) etc. etc.\nGiving work one by one can be very inefficient for quick tasks, as the time needed by a worker process to stop and get new work can be longer than it takes to actually complete the task. To solve this problem, you can control how many work items are handed out to each worker process at a time. This is known as chunking, and the number of work items is known as the chunk of work to perform.\nYou can control the number of work items to perform per worker (the chunk size) by setting the chunksize argument, e.g.\nsum_results = pool.map(add, a, b, chunksize=5)\nwould suggest to pool that each worker be given a chunk of five pieces of work. Note that this is just a suggestion, and pool may decide to use a slightly smaller or larger chunk size depending on the amount of work and the number of workers available.\nModify your asyncmap.py script and set the chunksize to 5 for both of the asynchronous maps for add and product. Re-run your script. You should see something like;\nAll the jobs are submitted, now we wait for results...\nWorker 10531 is processing add(1, 11)\nWorker 10532 is processing add(6, 16)\nWorker 10533 is processing product(6, 16)\nWorker 10534 is processing product(1, 11)\nWorker 10531 is processing add(2, 12)\nWorker 10532 is processing add(7, 17)\nWorker 10533 is processing product(7, 17)\nWorker 10534 is processing product(2, 12)\nWorker 10531 is processing add(3, 13)\nWorker 10533 is processing product(8, 18)\nWorker 10532 is processing add(8, 18)\nWorker 10534 is processing product(3, 13)\nWorker 10531 is processing add(4, 14)\nWorker 10533 is processing product(9, 19)\nWorker 10532 is processing add(9, 19)\nWorker 10534 is processing product(4, 14)\nWorker 10531 is processing add(5, 15)\nWorker 10533 is processing product(10, 20)\nWorker 10532 is processing add(10, 20)\nWorker 10534 is processing product(5, 15)\nSum of sums of 'a' and 'b' is 210\nSum of products of 'a' and 'b' is 935\nMy laptop has four workers. The first worker is assigned the first five items of work, i.e. add(1, 11) to add(5, 15), and it starts by running add(1, 11), hence why add(1, 11) is printed first.\nThe next worker is given the next five items of work, i.e. add(6, 16) to add(10,20), and starts by running add(6, 16), hence why add(6, 16) is printed second.\nThe next worker is given the next five items of work, i.e. product(1, 11) to product(5, 15), and it starts by running product(1, 11), hence why this is printed third.\nThe last worker is given the next five items of work, i.e. product(6, 16) to product(10, 20), and it starts by running product(6, 16), hence why this is printed fourth.\nOnce each worker has finished its first item of work, it moves onto its second. This is why add(2, 12), add(7, 17), product(2, 12) and product(7, 17) are printed next. Then, each worker moves onto its third piece of work etc. etc.\nIf you don’t specify the chunksize then it is equal to 1. When writing a new script you should experiment with different values of chunksize to find the value that gives best performance.\n\n\n\n\n\n\nExercise\n\n\n\nEdit your script written in answer to the second exercise of Parallel map/reduce, in which you count all of the words used in all Shakespeare plays in coundwords.py (e.g. an example answer is here).\nEdit the script so that you set the chunk size of the map.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n%%writefile countwords.py\n\nimport re\nimport sys\n\nfrom functools import reduce\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_words(file):\n    \"\"\"\n    Count the number of times every word in `file` occurs.\n\n    Args:\n        file (Path): the file to count the words in\n\n    Returns:\n        dict: a mapping of word to count\n    \"\"\"\n\n    all_words = {}\n\n    text = file.read_text()\n    words = text.split()\n\n    for word in words:\n        #lowercase the word and remove all\n        #characters that are not [a-z] or hyphen\n        word = word.lower()\n        match = re.search(r\"([a-z\\-]+)\", word)\n\n        if match:\n            word = match.groups()[0]\n\n            if word in all_words:\n                all_words[word] += 1\n            else:\n                all_words[word] = 1\n\n    return all_words\n\n\ndef reduce_dicts(dict1, dict2):\n    \"\"\"\n    Combine (reduce) the passed two dictionaries to return\n    a dictionary that contains the keys of both, where the\n    values are equal to the sum of values for each key\n    \"\"\"\n\n    # explicitly copy the dictionary, as otherwise\n    # we risk modifying 'dict1'\n    combined = {}\n\n    for key in dict1:\n        combined[key] = dict1[key]\n\n    for key in dict2:\n        if key in combined:\n            combined[key] += dict2[key]\n        else:\n            combined[key] = dict2[key]\n\n    return combined\n\nif __name__ == \"__main__\":\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        results = pool.map(count_words, files, chunksize=5)\n\n    words = reduce(reduce_dicts, results)\n\n    for key in sorted(words.keys()):\n        if words[key] &gt; 2000:\n            print(f\"{key} == {words[key]}\")\n\nWriting countwords.py\n\n\nWriting countwords.py\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\n\n\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nCell In[2], line 4\n      1 import urllib\n      2 import tarfile\n----&gt; 4 urllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\n      5 with tarfile.open(\"shakespeare.tar.bz2\") as tar:\n      6     tar.extractall()\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:240, in urlretrieve(url, filename, reporthook, data)\n    223 \"\"\"\n    224 Retrieve a URL into a temporary location on disk.\n    225 \n   (...)\n    236 data file as well as the resulting HTTPMessage object.\n    237 \"\"\"\n    238 url_type, path = _splittype(url)\n--&gt; 240 with contextlib.closing(urlopen(url, data)) as fp:\n    241     headers = fp.info()\n    243     # Just return the local path and the \"headers\" for file://\n    244     # URLs. No sense in performing a copy unless requested.\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:215, in urlopen(url, data, timeout, cafile, capath, cadefault, context)\n    213 else:\n    214     opener = _opener\n--&gt; 215 return opener.open(url, data, timeout)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:521, in OpenerDirector.open(self, fullurl, data, timeout)\n    519 for processor in self.process_response.get(protocol, []):\n    520     meth = getattr(processor, meth_name)\n--&gt; 521     response = meth(req, response)\n    523 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:630, in HTTPErrorProcessor.http_response(self, request, response)\n    627 # According to RFC 2616, \"2xx\" code indicates that the client's\n    628 # request was successfully received, understood, and accepted.\n    629 if not (200 &lt;= code &lt; 300):\n--&gt; 630     response = self.parent.error(\n    631         'http', request, response, code, msg, hdrs)\n    633 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:559, in OpenerDirector.error(self, proto, *args)\n    557 if http_err:\n    558     args = (dict, 'default', 'http_error_default') + orig_args\n--&gt; 559     return self._call_chain(*args)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:492, in OpenerDirector._call_chain(self, chain, kind, meth_name, *args)\n    490 for handler in handlers:\n    491     func = getattr(handler, meth_name)\n--&gt; 492     result = func(*args)\n    493     if result is not None:\n    494         return result\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:639, in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs)\n    638 def http_error_default(self, req, fp, code, msg, hdrs):\n--&gt; 639     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n\nHTTPError: HTTP Error 404: Not Found\n\n\n\npython -u countwords.py shakespeare\na == 10737\nall == 2687\nand == 17573\nare == 2530\nas == 4097\nbe == 4859\nbut == 4505\nby == 2584\ndo == 2944\nfor == 5395\ngood == 2075\nhave == 4425\nhe == 5005\nher == 3249\nhim == 3829\nhis == 4419\ni == 16856\nif == 2598\nin == 7624\nis == 6851\nit == 5894\nlord == 2071\nme == 5674\nmy == 8380\nno == 2784\nnot == 6323\no == 2316\nof == 11332\non == 2204\nshall == 2441\nshe == 2155\nsir == 2527\nso == 3574\nthat == 8006\nthe == 19443\nthee == 2196\nthis == 4627\nthou == 3719\nthy == 2465\nto == 13615\nwe == 2497\nwhat == 3608\nwill == 3634\nwith == 5280\nyou == 11108\nyour == 4832",
    "crumbs": [
      "Multicore (local) Parallel Programming",
      "Asynchronous Mapping"
    ]
  },
  {
    "objectID": "pages/answer_shakespeare_lambda.html",
    "href": "pages/answer_shakespeare_lambda.html",
    "title": "Introducing Parallel Python",
    "section": "",
    "text": "%%writefile countlines.py\n\nimport sys\nfrom functools import reduce\nfrom pathlib import Path\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\n# get all of the names of the plays from the command line\nfiles = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n# map the count_lines function against all of the\n# files listed in \"filenames\"\nplay_line_count = sorted(map(count_lines_in_file, files))\n\n# print out the filenames of the plays along with their line counts\nfor f, count in zip(files, play_line_count):\n    print(f\"{f} has {count} lines\")\n\ntotal = reduce(lambda x,y: x+y, play_line_count)\n\nprint(\"The total number of lines is %s.\" % total)\n\nOverwriting countlines.py\n\n\nOverwriting countlines.py\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\n\n\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nCell In[2], line 4\n      1 import urllib\n      2 import tarfile\n----&gt; 4 urllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\n      5 with tarfile.open(\"shakespeare.tar.bz2\") as tar:\n      6     tar.extractall()\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:240, in urlretrieve(url, filename, reporthook, data)\n    223 \"\"\"\n    224 Retrieve a URL into a temporary location on disk.\n    225 \n   (...)\n    236 data file as well as the resulting HTTPMessage object.\n    237 \"\"\"\n    238 url_type, path = _splittype(url)\n--&gt; 240 with contextlib.closing(urlopen(url, data)) as fp:\n    241     headers = fp.info()\n    243     # Just return the local path and the \"headers\" for file://\n    244     # URLs. No sense in performing a copy unless requested.\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:215, in urlopen(url, data, timeout, cafile, capath, cadefault, context)\n    213 else:\n    214     opener = _opener\n--&gt; 215 return opener.open(url, data, timeout)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:521, in OpenerDirector.open(self, fullurl, data, timeout)\n    519 for processor in self.process_response.get(protocol, []):\n    520     meth = getattr(processor, meth_name)\n--&gt; 521     response = meth(req, response)\n    523 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:630, in HTTPErrorProcessor.http_response(self, request, response)\n    627 # According to RFC 2616, \"2xx\" code indicates that the client's\n    628 # request was successfully received, understood, and accepted.\n    629 if not (200 &lt;= code &lt; 300):\n--&gt; 630     response = self.parent.error(\n    631         'http', request, response, code, msg, hdrs)\n    633 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:559, in OpenerDirector.error(self, proto, *args)\n    557 if http_err:\n    558     args = (dict, 'default', 'http_error_default') + orig_args\n--&gt; 559     return self._call_chain(*args)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:492, in OpenerDirector._call_chain(self, chain, kind, meth_name, *args)\n    490 for handler in handlers:\n    491     func = getattr(handler, meth_name)\n--&gt; 492     result = func(*args)\n    493     if result is not None:\n    494         return result\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:639, in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs)\n    638 def http_error_default(self, req, fp, code, msg, hdrs):\n--&gt; 639     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n\nHTTPError: HTTP Error 404: Not Found\n\n\n\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 2938 lines\nshakespeare/antonyandcleopatra has 3116 lines\nshakespeare/asyoulikeit has 3400 lines\nshakespeare/comedyoferrors has 3606 lines\nshakespeare/coriolanus has 3768 lines\nshakespeare/cymbeline has 3872 lines\nshakespeare/hamlet has 3877 lines\nshakespeare/juliuscaesar has 3884 lines\nshakespeare/kinglear has 3974 lines\nshakespeare/loveslabourslost has 4018 lines\nshakespeare/macbeth has 4064 lines\nshakespeare/measureforemeasure has 4108 lines\nshakespeare/merchantofvenice has 4123 lines\nshakespeare/merrywivesofwindsor has 4149 lines\nshakespeare/midsummersnightsdream has 4336 lines\nshakespeare/muchadoaboutnothing has 4338 lines\nshakespeare/othello has 4449 lines\nshakespeare/periclesprinceoftyre has 4516 lines\nshakespeare/romeoandjuliet has 4644 lines\nshakespeare/tamingoftheshrew has 4767 lines\nshakespeare/tempest has 5425 lines\nshakespeare/timonofathens has 5444 lines\nshakespeare/titusandronicus has 5486 lines\nshakespeare/troilusandcressida has 5526 lines\nshakespeare/twelfthnight has 5837 lines\nshakespeare/twogentlemenofverona has 5999 lines\nshakespeare/winterstale has 6046 lines\nThe total number of lines is 119713."
  },
  {
    "objectID": "pages/220-pool.html",
    "href": "pages/220-pool.html",
    "title": "Pool",
    "section": "",
    "text": "One of the core concurrent.futures features is concurrent.futures.ProcessPoolExecutor. This provides a pool of workers that can be used to parallelise a map.\nFor example, we have been working with examples like the following which run using the serial map function:\n\ndef square(x):\n    \"\"\"Function to return the square of the argument\"\"\"\n    return x * x\n\nr = [1, 2, 3, 4, 5]\nresult = map(square, r)\nprint(list(result))\n\n[1, 4, 9, 16, 25]\n\n\nTo convert this code to be able to run the function across multiple processors, we need to change it to look like:\n\n\npool.py\n\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef square(x):\n    \"\"\"Function to return the square of the argument\"\"\"\n    return x * x\n\nif __name__ == \"__main__\":\n    r = [1, 2, 3, 4, 5]\n    \n    # create a pool of workers\n    with ProcessPoolExecutor() as pool:\n        result = pool.map(square, r)\n\n    print(list(result))\n\nwhich, when run, gives us the same result:\npython pool.py\n    [1, 4, 9, 16, 25]\nThe core logic of the code has remained the same but we have had to make some changes in order to make it ready to support running in parallel:\n\nWe moved the code that calls the map into an if __name__ == \"__main__\" block. This is to ensure that only the master process create the pool of worker processes.\nWe have created a pool of workers using with ProcessPoolExecutor() as pool. Inside this block we can access the worker pool with the pool variable and once we leave the block, the workers will be automatically cleaned up.\nWe call pool.map instead of just map to make the mapping be performed by the workers.\n\nThe parallel work is conducted on the line\nresult = pool.map(square, r)\nThis performs a map of the function square over the list of items in r. The map is divided up over all of the workers in the pool. This means that, if you have 10 workers (e.g. if you have 10 cores), then each worker will perform only one tenth of the work. If you have 2 workers, then each worker will perform only half of the work.\nYou can verify that the square function is divided between your workers by using an os.getpid call, which will return the process ID (PID) of the worker. We can also manually set the number of worker processes that should be created by passing max_workers= to the ProcessPoolExecutor constructor. Edit your pool.py script and set the contents equal to:\n\n\npool.py\n\nimport os\nfrom concurrent.futures import ProcessPoolExecutor\nfrom functools import reduce\n\ndef square(x):\n    \"\"\"Function to return the square of the argument\"\"\"\n    print(f\"Worker {os.getpid()} calculating square of {x}\")\n    return x * x\n\nif __name__ == \"__main__\":\n    # create a pool of workers\n    with ProcessPoolExecutor(max_workers=2) as pool:\n        # create an array of 20 integers, from 1 to 20\n        r = range(1, 21)\n\n        result = pool.map(square, r)\n\n    total = reduce(lambda x, y: x + y, result)\n\n    print(f\"The sum of the square of the first 20 integers is {total}\")\n\nWorker 7116 calculating square of 1\nWorker 7117 calculating square of 2\nWorker 7116 calculating square of 3\nWorker 7116 calculating square of 4\nWorker 7117 calculating square of 5\nWorker 7117 calculating square of 6\nWorker 7117 calculating square of 7\nWorker 7117 calculating square of 8\nWorker 7117 calculating square of 9\nWorker 7117 calculating square of 10\nWorker 7116 calculating square of 11\nWorker 7117 calculating square of 12\nWorker 7116 calculating square of 13\nWorker 7117 calculating square of 14\nWorker 7116 calculating square of 15\nWorker 7117 calculating square of 16\nWorker 7116 calculating square of 17\nWorker 7116 calculating square of 18\nWorker 7116 calculating square of 19\nWorker 7117 calculating square of 20\nThe sum of the square of the first 20 integers is 2870\n(the exact PIDs of the workers, and the order in which they print will be different on your machine)\nYou can see in the output that there are two workers, signified by the two different worker PIDs. The work has been divided evenly amongst them.\n\n\n\n\n\n\nExercise\n\n\n\nEdit pool.py and change the value of max_workers. How is the work divided as you change the number of workers?\n\n\n\nUsing multiple pools in a single script\nYou can use more than one ProcessPoolExecutor in your script, but you should ensure that you use them one after another. The way ProcessPoolExecutor works is to fork your script into the team of workers when you create a ProcessPoolExecutor object. Each worker contains a complete copy of all of the functions and variables that exist at the time of the fork. This means that any changes after the fork will not be held by the other workers.\nIf you made a Python script called broken_pool.py with the contents:\n\n\npool.py\n\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef square(x):\n    \"\"\"Return the square of the argument\"\"\"\n    return x * x\n\nif __name__ == \"__main__\":\n\n    r = [1, 2, 3, 4, 5]\n\n    with ProcessPoolExecutor() as pool:\n        result = pool.map(square, r)\n\n        print(f\"Square result: {list(result)}\")\n\n        def cube(x):\n            \"\"\"Return the cube of the argument\"\"\"\n            return x * x * x\n\n        result = pool.map(cube, r)\n\n        print(f\"Cube result: {list(result)}\")\n\nand ran it you would see an error like:\nAttributeError: Can't get attribute 'cube' on &lt;module '__main__' from 'broken_pool.py'&gt;\nThe problem is that pool was created before the cube function. The worker copies of the script were thus created before cube was defined, and so don’t contain a copy of this function. This is one of the reasons why you should always define your functions above the if __name__ == \"__main__\" block.\nAlternatively, if you have to define the function in the __main__ block, then ensure that you create the pool after the definition. For example, one fix here is to create a second pool for the second map:\n\n\npool.py\n\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef square(x):\n    \"\"\"Return the square of the argument\"\"\"\n    return x * x\n\nif __name__ == \"__main__\":\n\n    r = [1, 2, 3, 4, 5]\n\n    with ProcessPoolExecutor() as pool:\n        result = pool.map(square, r)\n\n        print(f\"Square result: {list(result)}\")\n\n    def cube(x):\n        \"\"\"Return the cube of the argument\"\"\"\n        return x * x * x\n\n    with ProcessPoolExecutor() as pool:\n        result = pool.map(cube, r)\n\n        print(f\"Cube result: {list(result)}\")\n\nRunning this should print out\npython pool.py\nSquare result: [1, 4, 9, 16, 25]\nCube result: [1, 8, 27, 64, 125]",
    "crumbs": [
      "Multicore (local) Parallel Programming",
      "Pool"
    ]
  },
  {
    "objectID": "pages/990-contributors.html",
    "href": "pages/990-contributors.html",
    "title": "Contributors",
    "section": "",
    "text": "This course has been developed by the Jean Golding Insitute.\nThe materials were originally written by Christopher Woods https://chryswoods.com/parallel_python/, and revised by Matt Williams https://milliams.com/courses/parallel_python/.",
    "crumbs": [
      "Contributors"
    ]
  },
  {
    "objectID": "pages/answer_countlines_mean.html",
    "href": "pages/answer_countlines_mean.html",
    "title": "Introducing Parallel Python",
    "section": "",
    "text": "countlines.py\n\nimport glob\nimport sys\nimport statistics\n\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\nif __name__ == \"__main__\":\n    # get all of the names of the plays from the command line\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        # map the count_lines function against all of the\n        # files listed in \"filenames\"\n        play_line_count = pool.map(count_lines_in_file, files)\n        \n        # convert it to a list as we need to use the result in two places.\n        play_line_count = list(play_line_count)\n\n        for f, count in zip(files, play_line_count):\n            print(f\"{f} has {count} lines\")\n\n    total = sum(play_line_count)\n    print(f\"The total number of lines is {total}.\")\n\n    average = statistics.mean(play_line_count)  # This is a new line\n    print(f\"The average number of lines is {int(average)}.\")  # This is a new line\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines\nThe total number of lines is 119713.\nThe average number of lines is 4275."
  },
  {
    "objectID": "pages/980-summary.html",
    "href": "pages/980-summary.html",
    "title": "Summary",
    "section": "",
    "text": "You’ve now learned the basics of functional programming, and how to write parallel Python scripts that can run across the cores of your desktop, or across the processors of a distributed or HPC cluster.\nIf you want to learn more then take a look at the documentation for the in-built Python modules multiprocessing and concurrent.futures.\nThe MPI4Py documentation will give you a lot of detail on making more advanced parallel Python programs.",
    "crumbs": [
      "Summary"
    ]
  },
  {
    "objectID": "pages/110-functions.html",
    "href": "pages/110-functions.html",
    "title": "Functions as Objects",
    "section": "",
    "text": "Functional programming is based on treating a function in the same way as you would a variable or object. So, to start, we should first create a function. This will be a simple function that just adds together two numbers. Please type in the Python Console:\n\ndef add(x, y):\n    \"\"\"Simple function returns the sum of the arguments\"\"\"\n    return x + y\n\nThis is a very simple function that just returns the sum of its two arguments. Call the function using, e.g.\n\nadd(3, 7)\n\n10\n\n\nIn functional programming, a function is treated in exactly the same way as a variable or an object. This means that a function can be assigned to a variable, e.g. type\n\na = add\na(3, 7)\n\n10\n\n\nWe see the same output. Here, we have assigned the function add to the variable a. So how does this work?\nFor variables, you should be comfortable with the idea that a variable refers to a piece of data. For functional programming, the code of a function is also treated like a piece of data. The code\n\ndef add(x, y):\n    \"\"\"Simple function returns the sum of the arguments\"\"\"\n    return x + y\n\ncreates a new piece of data (the code to add together x and y), and creates a new name add which points to that code. When we then typed\n\na = add\n\nwe created a new variable a which refers to the same piece of code data that add pointed to. Now both a and add or point to the same data, i.e. the same code that adds together the two arguments (e.g. add(3, 7) and a(3, 7) will call the same code, and give the same result).\nThis means that “function” is a type, in the same way that “integer”, “string” and “floating point number” are types.\n\nProperties of a Function\nJust as “integer” and “string” have properties, so does “function”. Type into the Python Console:\nadd.__[TAB]\n(where [TAB] means that you should press the tab key)\nThis should show something like\nadd.__call__          add.__dict__          add.__hash__          add.__reduce_ex__\nadd.__class__         add.__doc__           add.__init__          add.__repr__\nadd.__closure__       add.__format__        add.__module__        add.__setattr__\nadd.__code__          add.__get__           add.__name__          add.__sizeof__\nadd.__defaults__      add.__getattribute__  add.__new__           add.__str__\nadd.__delattr__       add.__globals__       add.__reduce__        add.__subclasshook__\nThis is the list of properties (functions and variables) of a function. The most interesting variables are __name__ and __doc__. Try typing\n\nadd.__name__\n\n'add'\n\n\n\nadd.__doc__\n\n'Simple function returns the sum of the arguments'\n\n\nFrom the output, can you guess what these two variables contain?\n\n\nFunctions as Arguments\nAs well as assigning functions to variables, you can also pass functions as arguments. Type this into the Console:\n\ndef call_function(func, arg1, arg2):\n    \"\"\"\n    Simple function that calls the function 'func' with  \n    arguments 'arg1' and 'arg2', returning the result\n    \"\"\"\n    return func(arg1, arg2)\n\ncall_function(add, 3, 7)\n\n10\n\n\nThe function call_function takes three arguments. The first is the function to be called. The second two arguments are the arguments that will be passed to that function. The code in call_function simply calls func using the arguments arg1 and arg2. So far, so useless…\nHowever, let us now create another function, called diff:\n\ndef diff(x, y):\n    \"\"\"\n    Simple function that returns the difference of\n    its arguments\n    \"\"\"\n    return x - y\n\nand then type\n\ncall_function(diff, 9, 2)\n\n7\n\n\nNow we have passed the function diff to call_function, and so func(arg1, arg2) has used the code contained in diff, e.g. calculating the difference of the two numbers.\nYou are probably now wondering how has this helped? Well, let us now change call_function:\n\ndef call_function(func, arg1, arg2):\n    \"\"\"\n    Simple function that returns the difference of\n    its arguments\n    \"\"\"\n    print(f\"Calling function {func.__name__} with arguments {arg1} and {arg2}.\")\n    result = func(arg1, arg2)\n    print(f\"The result is {result}\")\n    return result\n\n\ncall_function(add, 3, 7)\n\nCalling function add with arguments 3 and 7.\nThe result is 10\n\n\n10\n\n\n\ncall_function(diff, 9, 2)\n\nCalling function diff with arguments 9 and 2.\nThe result is 7\n\n\n7\n\n\nThe new call_function is now doing something useful. It is printing out extra information about our functions, and can do that for any function (which accepts two arguments) that we pass.",
    "crumbs": [
      "Functional Programming",
      "Functions as Objects"
    ]
  },
  {
    "objectID": "pages/answer_shakespeare_reduce.html",
    "href": "pages/answer_shakespeare_reduce.html",
    "title": "Introducing Parallel Python",
    "section": "",
    "text": "%%writefile countlines.py\n\nimport sys\nfrom functools import reduce\nfrom pathlib import Path\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\n# get all of the names of the plays from the command line\nfiles = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n# map the count_lines function against all of the\n# files listed in \"filenames\"\nplay_line_count = list(map(count_lines_in_file, files))\n\n# print out the filenames of the plays along with their line counts\nfor f, count in zip(files, play_line_count):\n    print(f\"{f} has {count} lines\")\n\n\n### This is the new bit of the code\n\ndef add(x, y):\n    \"\"\"Return the sum of the two arguments\"\"\"\n    return x + y\n\ntotal = reduce(add, play_line_count)\n\nprint(\"The total number of lines is %s.\" % total)\n\nWriting countlines.py\n\n\nOverwriting countlines.py\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\n\n\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nCell In[2], line 4\n      1 import urllib\n      2 import tarfile\n----&gt; 4 urllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\n      5 with tarfile.open(\"shakespeare.tar.bz2\") as tar:\n      6     tar.extractall()\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:240, in urlretrieve(url, filename, reporthook, data)\n    223 \"\"\"\n    224 Retrieve a URL into a temporary location on disk.\n    225 \n   (...)\n    236 data file as well as the resulting HTTPMessage object.\n    237 \"\"\"\n    238 url_type, path = _splittype(url)\n--&gt; 240 with contextlib.closing(urlopen(url, data)) as fp:\n    241     headers = fp.info()\n    243     # Just return the local path and the \"headers\" for file://\n    244     # URLs. No sense in performing a copy unless requested.\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:215, in urlopen(url, data, timeout, cafile, capath, cadefault, context)\n    213 else:\n    214     opener = _opener\n--&gt; 215 return opener.open(url, data, timeout)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:521, in OpenerDirector.open(self, fullurl, data, timeout)\n    519 for processor in self.process_response.get(protocol, []):\n    520     meth = getattr(processor, meth_name)\n--&gt; 521     response = meth(req, response)\n    523 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:630, in HTTPErrorProcessor.http_response(self, request, response)\n    627 # According to RFC 2616, \"2xx\" code indicates that the client's\n    628 # request was successfully received, understood, and accepted.\n    629 if not (200 &lt;= code &lt; 300):\n--&gt; 630     response = self.parent.error(\n    631         'http', request, response, code, msg, hdrs)\n    633 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:559, in OpenerDirector.error(self, proto, *args)\n    557 if http_err:\n    558     args = (dict, 'default', 'http_error_default') + orig_args\n--&gt; 559     return self._call_chain(*args)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:492, in OpenerDirector._call_chain(self, chain, kind, meth_name, *args)\n    490 for handler in handlers:\n    491     func = getattr(handler, meth_name)\n--&gt; 492     result = func(*args)\n    493     if result is not None:\n    494         return result\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:639, in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs)\n    638 def http_error_default(self, req, fp, code, msg, hdrs):\n--&gt; 639     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n\nHTTPError: HTTP Error 404: Not Found\n\n\n\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines\nThe total number of lines is 119713."
  },
  {
    "objectID": "pages/answer_countlines_operator.html",
    "href": "pages/answer_countlines_operator.html",
    "title": "Introducing Parallel Python",
    "section": "",
    "text": "countlines.py\n\nimport glob\nimport sys\nimport operator\n\nfrom functools import reduce\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\nif __name__ == \"__main__\":\n    # get all of the names of the plays from the command line\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        # map the count_lines function against all of the\n        # files listed in \"filenames\"\n        play_line_count = pool.map(count_lines_in_file, files)\n        \n        # convert it to a list as we need to use the result in two places.\n        play_line_count = list(play_line_count)\n\n        for f, count in zip(files, play_line_count):\n            print(f\"{f} has {count} lines\")\n\n    total = reduce(operator.add, play_line_count)\n    print(f\"The total number of lines is {total}.\")\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines\nThe total number of lines is 119713."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to a short course that will teach you how to write Python scripts that can take advantage of the processing power of multicore processors and large compute clusters. While this course is based on Python, the core ideas of functional programming and parallel functional programming are applicable to a wide range of languages.\nTo follow this course you should already have a good basic understanding of Python, e.g. loops, functions, containers and classes. This course will rely on you understanding the material presented in the Beginning Python and Intermediate Python courses.\nThis is a short course that will give you a taste of functional programming and how it can be used to write efficient parallel code. Please work through the course at your own pace. Python is best learned by using it, so please copy out and play with the examples provided, and also have a go at the exercises.\n=========== This course is aimed at the Python developer who wants to learn how to do useful data analysis tasks. Over the years, Python has become a very popular tool for analysing data. These days it comes with support from many tools to do machine learning, data querying, neural networks and exploratory analysis. In this course we will investigate the use of scikit-learn for machine learning to discover things about whatever data may come across your desk.\nFor the purpose of this course we will be using a free tool called JupyterLab which provides you with a local editor and Python terminal in your web browser. Setting up instructions can be found here.\n\nIntended learning outcomes\nBy the end of this course, you will:\n\nKnow how to use Jupyter Notebooks.\nBe familiar with scikit-learn and seaborn.\nKnow how to perform simple machine learning tasks.\n\n\n\nHow to read this documentation\nIn this documentation, any time that we are seeing a small snippet of Python code, we’ll see it written in a grey box like the following:\nprint(\"Hello, Python\")\nIf the commands are executed by the machine we will see the output of them below enclosed on a vertical purple line:\n\nprint(\"Hello, Python!\")\n\nHello, Python!\n\n\nBy contrast, you will see larger peces of code as scripts with a given name, e.g. script.py, in a code block with darker header:\n\n\nscript.py\n\ngreeting = \"Hello\"\nname = input(\"What is your name? \")\nprint(greeting, name)\n\nWe may ask you to run a script using the Command Prompt (Windows) or Terminal (Mac and Linux). We will show you what commands to run and will look like this:\n\n\nTerminal/Command Prompt\n\npython script.py\n\nPlease note that sometimes we will skip showing the execution of scripts on the Terminal/Command Prompt box, but we will assume you to run the script on your.\nIn some cases we will introduce general programming concepts and structures using pseudocode, a high-level, easy-to-read syntax close to natural language. This should not be confused with Python code and cannot be executed on your machine, but it is useful to describe how your code should behave. Here there is an example:\nFOR EACH sample IN my_study\n    IF (sample.value &gt; 100)\n        DO SOMETHING\n    OTHERWISE\n        DO SOMETHING ELSE\nThere are some exercises along this course, and it is important you try to answer them yourself to understand how Python works. Exercises are shown in blue boxes followed by a yellow box that contains the answer of each exercise. We recommend you to try to answer each exercise yourself before looking at the solution.\n\n\n\n\n\n\nExercise\n\n\n\nThis is an exercise. You will need to click in the below box to see the answer.\n\n\n\n\n\n\n\n\nAnswer (click to open)\n\n\n\n\n\nThis is the answer.\n\n\n\nLast, we will highlight important points using green boxes like this one:\n\n\n\n\n\n\nKey points\n\n\n\nThese are important concepts and technical notes.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "pages/120-map.html",
    "href": "pages/120-map.html",
    "title": "Mapping Functions",
    "section": "",
    "text": "In many situations you would like to apply the same function to lots of different pieces of data. For example, let’s create two arrays of numbers, and use our add function to add pairs of numbers together. In the Python Console type:\n\ndef add(x, y):\n    \"\"\"Simple function returns the sum of the arguments\"\"\"\n    return x + y\n\n\ndef multiply(x, y):\n    \"\"\"\n    Simple function that returns the product of the\n    two arguments\n    \"\"\"\n    return x * y\n\n\na = [1, 2, 3, 4, 5]\nb = [6, 7, 8, 9, 10]\n\nresult = []\n\nfor i, j in zip(a, b):\n    r = add(i, j)\n    result.append(r)\n\nprint(result)\n\n[7, 9, 11, 13, 15]\n\n\nThe above code has looped over every pair of numbers in the lists a and b, and has called the function add for each pair. Each result is appended to the list result, which is printed at the end of the loop.\nApplying the same function to every item in a list (or pair of lists) of data is really common. For example, in a molecular simulation, you may want to loop over a list of every molecule and call a calculate_energy function for each one. In a fluid dynamics simulation, you may want to loop over a list of grid points and call a solve_gridpoint function for each one. This pattern, of calling the same function for each element of a list (or set of lists) of data, is called mapping. In the above example, we have mapped the function add onto the lists a and b, giving us result.\nThe above code mapped the function add. How about if we wanted to map our diff or multiply functions? One option would be to copy out this code again. A better solution would be to use functional programming to write our own mapping function.\n\ndef mapper(func, arg1, arg2):\n    \"\"\"\n    This will map the function 'func' to each pair\n    of arguments in the list 'arg1' and 'arg2', returning\n    the result\n    \"\"\"\n\n    res = []\n\n    for i, j in zip(arg1, arg2):\n        r = func(i, j)\n        res.append(r)\n\n    return res\n\n\nmapper(add, a, b)\n\n[7, 9, 11, 13, 15]\n\n\n\nmapper(multiply, a, b)\n\n[6, 14, 24, 36, 50]\n\n\nThe mapper function takes as its first argument the function to be mapped. The other arguments are the two lists of data for the mapping. The part zip(arg1, arg2) takes the two arguments and returns an interator which can go through them both at the same time. As soon as one of them runs out of elements, it will stop. The mapper function then loops through each of these pairs of data, calling func for each pair, and storing the result in the list res. This is then returned at the end.\nBecause the mapper function calls the mapped function using the argument func, it can map any function that is passed to it, as long as that function accepts two arguments. For example, let us now create a completely different function to map:\n\nimport math\n\ndef calc_distance(point1, point2):\n    \"\"\"\n    Function to calculate and return the distance between\n    two points\n    \"\"\"\n\n    dx2 = (point1[0] - point2[0]) ** 2\n    dy2 = (point1[1] - point2[1]) ** 2\n\n    return math.sqrt(dx2 + dy2)\n\nThis has created a function that calculates the distance between two points. Let’s now create two lists of points and use mapper to control the calculation of distances between points:\n\npoints1 = [(1.0, 1.0), (2.0, 2.0), (3.0, 3.0)]\npoints2 = [(4.0, 4.0), (5.0, 5.0), (6.0, 6.0)]\n\nmapper(calc_distance, points1, points2)\n\n[4.242640687119285, 4.242640687119285, 4.242640687119285]\n\n\nAs long as the function and the data are compatible, the mapper function will work.\n\nStandard Map\nMapping is so common and useful that it is built in as a standard Python function, called map. For example:\n\nmap(calc_distance, points1, points2)\n\n&lt;map at 0x10f478310&gt;\n\n\nThis is perhaps a little unexpected as Python hasn’t actually given us the answer. Instead, the built-in map function has returned an object which is ready and waiting to perform the calculation you’ve asked, but won’t actually run those calculations unitl you request the result. This can be useful because by evaluating the map “lazily”, you can avoid unnecessary computation. The technical term for the thing that has been returned is an iterator. You can use this object in a for loop just fine but you can only loop over it once.\nIf you want to force Python to evaluate the map and give you the answers, you can turn it into a list usig the list function:\n\ndistances = map(calc_distance, points1, points2)\nlist(distances)\n\n[4.242640687119285, 4.242640687119285, 4.242640687119285]\n\n\nYou should see that your calc_distances function has been mapped to all of the pairs of points.\nThere is one more niggle to be aware of, and that is that an iterator object can only be used one before it is “exhausted”. If we try to get the result of a map in two places we see the following:\n\ndistances = map(calc_distance, points1, points2)\nprint(list(distances))\nprint(list(distances))\n\n[4.242640687119285, 4.242640687119285, 4.242640687119285]\n[]\n\n\nYou see that the second time we converted distances to a list it created an empty list. If you need to use the result of a map in multiple places, you should convert it to a list once, and then use that list result:\n\ndistances = map(calc_distance, points1, points2)\ndistance_list = list(distances)\nprint(distance_list)\nprint(distance_list)\n\n[4.242640687119285, 4.242640687119285, 4.242640687119285]\n[4.242640687119285, 4.242640687119285, 4.242640687119285]\n\n\nThe standard map function behaves very similarly to your hand-written mapper function, returing an iterator containing the result of applying your function to each item of data.\nOne advantage of map is that it knows how to handle multiple arguments. For example, let’s create a function that only maps a single argument:\n\ndef square(x):\n    \"\"\"\n    Simple function to return the square of\n    the passed argument\n    \"\"\"\n    return x * x\n\nNow, let’s try to use your handwritten mapper function to map square onto a list of numbers:\n\nnumbers = [1, 2, 3, 4, 5]\n\nresult = mapper(square, numbers)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[14], line 3\n      1 numbers = [1, 2, 3, 4, 5]\n----&gt; 3 result = mapper(square, numbers)\n\nTypeError: mapper() missing 1 required positional argument: 'arg2'\n\n\n\nThis raises an exception since we wrote our mapper function so that it mapped functions that expected two arguments. That meant that our mapper function needs three arguments; the mapped function plus two lists of arguments.\nThe standard map function can handle different numbers of arguments:\n\nresult = map(square, numbers)\n\nlist(result)\n\n[1, 4, 9, 16, 25]\n\n\nThe standard map function can work with mapping functions that accept any number of arguments. If the mapping function accepts n arguments, then you must pass n+1 arguments to map, i.e. the mapped function, plus n lists of arguments:\n\ndef find_smallest(arg1, arg2, arg3):\n    \"\"\"\n    Function used to return the smallest value out \n    of 'arg1', 'arg2' and 'arg3'\n    \"\"\"\n\n    return min(arg1, arg2, arg3)\n\na = [1, 2, 3, 4, 5]\nb = [5, 4, 3, 2, 1]\nc = [1, 2, 1, 2, 1]\n\nresult = map(find_smallest, a, b, c)\n\nlist(result)\n\n[1, 2, 1, 2, 1]\n\n\nIs this output what you expect?\n\n\n\n\n\n\nExercise\n\n\n\nDownload and unpack the file shakespeare.tar.bz2, e.g. type into a Python Console:\nimport urllib.request\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\nThis has created a directory called shakespeare that contains the full text of many of Shakespeare’s plays.\nYour task is to write a Python script, called countlines.py, that will count the total number of lines in each of these Shakespeare plays, e.g. that can be run in the Terminal with:\npython countlines.py\nTo do this, first you need a function that counts the number of lines in a file. An example functions is:\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\nThen, use the standard map function to count the number of lines in each Shakespeare play, printing the result as a list.\nYou can get a sorted list of all the files in a directory called shakespeare with:\n\nfrom pathlib import Path\nfiles = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nimport sys\nfrom pathlib import Path\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\n# get all of the names of the plays from the command line\nfiles = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n# map the count_lines function against all of the\n# files listed in \"filenames\"\nplay_line_count = map(count_lines_in_file, files)\n\n# print out the filenames of the plays along with their line counts\nfor f, count in zip(files, play_line_count):\n    print(f\"{f} has {count} lines\")\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines",
    "crumbs": [
      "Functional Programming",
      "Mapping Functions"
    ]
  },
  {
    "objectID": "pages/answer_countlines_sum.html",
    "href": "pages/answer_countlines_sum.html",
    "title": "Introducing Parallel Python",
    "section": "",
    "text": "countlines.py\n\nimport glob\nimport sys\n\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\nif __name__ == \"__main__\":\n    # get all of the names of the plays from the command line\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        # map the count_lines function against all of the\n        # files listed in \"filenames\"\n        play_line_count = pool.map(count_lines_in_file, files)\n        \n        # convert it to a list as we need to use the result in two places.\n        play_line_count = list(play_line_count)\n\n        for f, count in zip(files, play_line_count):\n            print(f\"{f} has {count} lines\")\n\n    total = sum(play_line_count)\n    print(f\"The total number of lines is {total}.\")\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines\nThe total number of lines is 119713."
  },
  {
    "objectID": "pages/230-map-reduce.html",
    "href": "pages/230-map-reduce.html",
    "title": "Parallel map/reduce",
    "section": "",
    "text": "The concurrent.futures.ProcessPoolExecutor provides an excellent mechanism for the parallelisation of map/reduce style calculations. The standard map can be almost directly replaced with a ProcessPoolExecutor.map and the reduce function can be used as-is. Note than the reduction will not be parallelised as it is, in general, a serial operation.\nAs we have seen though, some changes are needed such as putting the code in an if __name__ == \"__main__\" block. The largest remaining difference is how ProcessPoolExecutor treats lambda functions.\n\nProcessPoolExecutor doesn’t support lambda functions\nOne of the annoying limitations of the current version of multiprocessing (the underlying module for ProcessPoolExecutor) is that it does not support anonymous (lambda) functions. The mapping function has to be created using the def name(args) syntax. The reason is because Python currently doesn’t pickle functions correctly (i.e. Python cannot convert the code of a function to a binary array of data that can be transmitted to the worker copies of the script. In contrast, Python can correctly pickle most argument types, so can send arguments to the workers).\n\n\n\n\n\n\nExercise\n\n\n\nEdit your countlines.py script that you wrote for Part 1 so that you use concurrent.futures to parallelise the counting of lines. Note that you will not be able to use lambda in the pool.map function.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\ncountlines.py\n\nimport glob\nimport sys\n  \nfrom functools import reduce\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\nif __name__ == \"__main__\":\n    # get all of the names of the plays from the command line\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        # map the count_lines function against all of the\n        # files listed in \"filenames\"\n        play_line_count = pool.map(count_lines_in_file, files)\n        \n        # convert it to a list as we need to use the result in two places.\n        play_line_count = list(play_line_count)\n\n        for f, count in zip(files, play_line_count):\n            print(f\"{f} has {count} lines\")\n\n    total = reduce(lambda x, y: x + y, play_line_count)\n    print(f\"The total number of lines is {total}.\")\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines\nThe total number of lines is 119713.\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nBelow are two functions. The first counts the number of times every word in a file appears in that file, returning the result as a dictionary (the key is the word, the value is the number of times it appears). The second function combines (reduces) two dictionaries together.\n\n\ncountwords.py\n\nimport re\n\n\ndef count_words(file):\n    \"\"\"\n    Count the number of times every word in `file` occurs.\n\n    Args:\n        file (Path): the file to count the words in\n\n    Returns:\n        dict: a mapping of word to count\n    \"\"\"\n\n    all_words = {}\n\n    text = file.read_text()\n    words = text.split()\n\n    for word in words:\n        #lowercase the word and remove all\n        #characters that are not [a-z] or hyphen\n        word = word.lower()\n        match = re.search(r\"([a-z\\-]+)\", word)\n\n        if match:\n            word = match.groups()[0]\n\n            if word in all_words:\n                all_words[word] += 1\n            else:\n                all_words[word] = 1\n\n    return all_words\n\n\ndef reduce_dicts(dict1, dict2):\n    \"\"\"\n    Combine (reduce) the passed two dictionaries to return\n    a dictionary that contains the keys of both, where the\n    values are equal to the sum of values for each key\n    \"\"\"\n\n    # explicitly copy the dictionary, as otherwise\n    # we risk modifying 'dict1'\n    combined = {}\n\n    for key in dict1:\n        combined[key] = dict1[key]\n\n    for key in dict2:\n        if key in combined:\n            combined[key] += dict2[key]\n        else:\n            combined[key] = dict2[key]\n\n    return combined\n\nUse the above two functions to write a parallel Python script called countwords.py that counts how many times each word used by Shakespeare appears in all of his plays, e.g. by using the command line call\npython countwords.py\nHave your script print out every word that appears more than 2000 times across all of the plays. The words should be printed out in alphabetical order, and printed together with the number of times that they are used.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\ncountwords.py\n\nimport re\nimport sys\n\nfrom functools import reduce\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_words(file):\n    \"\"\"\n    Count the number of times every word in `file` occurs.\n\n    Args:\n        file (Path): the file to count the words in\n\n    Returns:\n        dict: a mapping of word to count\n    \"\"\"\n\n    all_words = {}\n\n    text = file.read_text()\n    words = text.split()\n\n    for word in words:\n        #lowercase the word and remove all\n        #characters that are not [a-z] or hyphen\n        word = word.lower()\n        match = re.search(r\"([a-z\\-]+)\", word)\n\n        if match:\n            word = match.groups()[0]\n\n            if word in all_words:\n                all_words[word] += 1\n            else:\n                all_words[word] = 1\n\n    return all_words\n\n\ndef reduce_dicts(dict1, dict2):\n    \"\"\"\n    Combine (reduce) the passed two dictionaries to return\n    a dictionary that contains the keys of both, where the\n    values are equal to the sum of values for each key\n    \"\"\"\n\n    # explicitly copy the dictionary, as otherwise\n    # we risk modifying 'dict1'\n    combined = {}\n\n    for key in dict1:\n        combined[key] = dict1[key]\n\n    for key in dict2:\n        if key in combined:\n            combined[key] += dict2[key]\n        else:\n            combined[key] = dict2[key]\n\n    return combined\n\nif __name__ == \"__main__\":\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        results = pool.map(count_words, files)\n\n    words = reduce(reduce_dicts, results)\n\n    for key in sorted(words.keys()):\n        if words[key] &gt; 2000:\n            print(f\"{key} == {words[key]}\")\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countwords.py shakespeare\na == 10737\nall == 2687\nand == 17573\nare == 2530\nas == 4097\nbe == 4859\nbut == 4505\nby == 2584\ndo == 2944\nfor == 5395\ngood == 2075\nhave == 4425\nhe == 5005\nher == 3249\nhim == 3829\nhis == 4419\ni == 16856\nif == 2598\nin == 7624\nis == 6851\nit == 5894\nlord == 2071\nme == 5674\nmy == 8380\nno == 2784\nnot == 6323\no == 2316\nof == 11332\non == 2204\nshall == 2441\nshe == 2155\nsir == 2527\nso == 3574\nthat == 8006\nthe == 19443\nthee == 2196\nthis == 4627\nthou == 3719\nthy == 2465\nto == 13615\nwe == 2497\nwhat == 3608\nwill == 3634\nwith == 5280\nyou == 11108\nyour == 4832",
    "crumbs": [
      "Multicore (local) Parallel Programming",
      "Parallel map/reduce"
    ]
  },
  {
    "objectID": "pages/200-multicore-programming.html",
    "href": "pages/200-multicore-programming.html",
    "title": "Multicore (local) Parallel Programming",
    "section": "",
    "text": "You have now learned how to use functional programming to write your Python script as a set of functions that can be mapped against or used to reduce lists of data. In the next parts of the course you will learn how to use functional programming to parallelise a Python script. In this part, you will learn how to parallelise a script over the cores of a single computer, while in the next part you will see how to parallelise a script across a cluster of computer nodes.",
    "crumbs": [
      "Multicore (local) Parallel Programming"
    ]
  },
  {
    "objectID": "pages/310-distributed-map-reduce.html",
    "href": "pages/310-distributed-map-reduce.html",
    "title": "Distributed map/reduce",
    "section": "",
    "text": "MPI4Py provides a low-level interface for creating full MPI-style programs but it also has a simpler API which allow you to call submit() which is equivalent of Pool.apply and map which provides the features of Pool.map and Pool.starmap all in one. You can find out a lot about it in the documentation.\n\n\nmapreduce.py\n\n\nfrom functools import reduce\n\nfrom mpi4py.futures import MPIPoolExecutor\n\ndef product(x, y):\n    \"\"\"Return the product of the arguments\"\"\"\n    return x*y\n\ndef sum(x, y):\n    \"\"\"Return the sum of the arguments\"\"\"\n    return x+y\n\nif __name__ == \"__main__\":\n\n    a = range(1,101)\n    b = range(101, 201)\n\n    with MPIPoolExecutor() as executor:\n        results = executor.map(product, a, b)\n\n    total = reduce(sum, results)\n\n    print(\"Sum of the products equals %d\" % total)\n\nYou’ll see that the only change from how we were running it previously is that the pool creation has changed from something like:\nwith ProcessPoolExecutor() as pool:\n    results = executor.map(product, a, b)\nto\nwith MPIPoolExecutor() as executor:\n    results = executor.map(product, a, b)\nWe’ve also had to import the module with from mpi4py.futures import MPIPoolExecutor.\nThe way in which you run the script will depend on the version on MPI that you have installed on your system. This is outside of the scope of this course and the best approach is to talk to your local HPC team.\nIn summary, you run the script through a standard MPI tool called mpiexec who’s job it is to set up the communication between the potentially multiple computers taking part in the calculation and start your Python script on each. This will usually look something like:\nmpiexec -n 1 -usize 17 python mapreduce.py\nwhich will start one process which manages the workers and 16 workers to run the map over. The number of workers you create should depend on the cluster that you are running on. Again, talk to your local HPC team, based on the example mpiexec line above they’ll know what to do.\nThe output of the script should look something like:\nSum of the products equals 843350",
    "crumbs": [
      "Multi-node (distributed/cluster) Parallel Programming",
      "Distributed map/reduce"
    ]
  },
  {
    "objectID": "pages/answer_shakespeare_map.html",
    "href": "pages/answer_shakespeare_map.html",
    "title": "Introducing Parallel Python",
    "section": "",
    "text": "import sys\nfrom pathlib import Path\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\n# get all of the names of the plays from the command line\nfiles = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n# map the count_lines function against all of the\n# files listed in \"filenames\"\nplay_line_count = map(count_lines_in_file, files)\n\n# print out the filenames of the plays along with their line counts\nfor f, count in zip(files, play_line_count):\n    print(f\"{f} has {count} lines\")\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines"
  },
  {
    "objectID": "pages/100-functional-programming.html",
    "href": "pages/100-functional-programming.html",
    "title": "Functional Programming",
    "section": "",
    "text": "To understand how best to write efficient parallel programs in Python, we first need to gain an understanding of “Functional Programming”. This is a style of programming in which functions are treated and manipulated as objects, i.e. functions can be assigned to variables, they can be passed as arguments, and they can be stored in containers along with other data.\nUsing the idea of functional programming, we can write parallel code that works by running lots of functions in parallel on large amounts of data. Your job, as a parallel functional programmer, is to design these functions. You then connect them together, with their dependencies, to create a team that can be distributed across the cores of a processor, or nodes of a cluster.\nFunctional programming is not the only way of writing an efficient parallel program. Other examples are shared-memory parallelism (e.g. check out the OpenMP course) or message passing (e.g. check out the MPI course). However, functional programming is, in my opinion, the easiest and most efficient way of extracting good performance from a parallel Python program.\nFunctional programming is useful also in its own right, and adopting it as a programming style can improve the readability and efficiency of even single-threaded Python code. It can make your intention as a programmer clearer to other developers, it can limit the amount of code duplication or retyping, and can also reduce the number of lines of code needed to represent your algorithm.",
    "crumbs": [
      "Functional Programming"
    ]
  },
  {
    "objectID": "pages/answer_shakespeare_countwords.html",
    "href": "pages/answer_shakespeare_countwords.html",
    "title": "Introducing Parallel Python",
    "section": "",
    "text": "countwords.py\n\nimport re\nimport sys\n\nfrom functools import reduce\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_words(file):\n    \"\"\"\n    Count the number of times every word in `file` occurs.\n\n    Args:\n        file (Path): the file to count the words in\n\n    Returns:\n        dict: a mapping of word to count\n    \"\"\"\n\n    all_words = {}\n\n    text = file.read_text()\n    words = text.split()\n\n    for word in words:\n        #lowercase the word and remove all\n        #characters that are not [a-z] or hyphen\n        word = word.lower()\n        match = re.search(r\"([a-z\\-]+)\", word)\n\n        if match:\n            word = match.groups()[0]\n\n            if word in all_words:\n                all_words[word] += 1\n            else:\n                all_words[word] = 1\n\n    return all_words\n\n\ndef reduce_dicts(dict1, dict2):\n    \"\"\"\n    Combine (reduce) the passed two dictionaries to return\n    a dictionary that contains the keys of both, where the\n    values are equal to the sum of values for each key\n    \"\"\"\n\n    # explicitly copy the dictionary, as otherwise\n    # we risk modifying 'dict1'\n    combined = {}\n\n    for key in dict1:\n        combined[key] = dict1[key]\n\n    for key in dict2:\n        if key in combined:\n            combined[key] += dict2[key]\n        else:\n            combined[key] = dict2[key]\n\n    return combined\n\nif __name__ == \"__main__\":\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        results = pool.map(count_words, files)\n\n    words = reduce(reduce_dicts, results)\n\n    for key in sorted(words.keys()):\n        if words[key] &gt; 2000:\n            print(f\"{key} == {words[key]}\")\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\npython countwords.py shakespeare\na == 10737\nall == 2687\nand == 17573\nare == 2530\nas == 4097\nbe == 4859\nbut == 4505\nby == 2584\ndo == 2944\nfor == 5395\ngood == 2075\nhave == 4425\nhe == 5005\nher == 3249\nhim == 3829\nhis == 4419\ni == 16856\nif == 2598\nin == 7624\nis == 6851\nit == 5894\nlord == 2071\nme == 5674\nmy == 8380\nno == 2784\nnot == 6323\no == 2316\nof == 11332\non == 2204\nshall == 2441\nshe == 2155\nsir == 2527\nso == 3574\nthat == 8006\nthe == 19443\nthee == 2196\nthis == 4627\nthou == 3719\nthy == 2465\nto == 13615\nwe == 2497\nwhat == 3608\nwill == 3634\nwith == 5280\nyou == 11108\nyour == 4832"
  },
  {
    "objectID": "pages/210-multiprocessing.html",
    "href": "pages/210-multiprocessing.html",
    "title": "Parallel Python",
    "section": "",
    "text": "Python has many libraries available to help you parallelise your scripts across the cores of a single multicore computer. The traditional option is the multiprocessing library but since Python 3.2 (2011) the concurrent.futures module has provided a consistent interface to many ways of running code in parallel.\nYou can find all the details of how to use these features in Python in the the official documentation page for concurrent.futures and some under-the-hood details in the multiprocessing documentation.\nOne of the first thing to understand is what your computer hardware is capable of, primarily, how many CPU cores it has. Python provides a function in the os module called cpu_count which returns the number of CPUs (computer cores) available on your computer to be used for a parallel program:\n\nimport os\n\nos.cpu_count()\n\n11\n\n\nNearly all modern computers have several processor cores, so you should see that you have at least 2, and perhaps as many as 40 available on your machine. Each of these cores is available to do work, in parallel, as part of your Python script. For example, if you have two cores in your computer, then your script should ideally be able to do two things at once. Equally, if you have forty cores available, then your script should ideally be able to do forty things at once.\nconcurrent.futures provides a number of ways of running your code in parallel and in this course we will be focussing on its process pool executor which allows your script to do lots of things at once by actually running multiple copies of your script in parallel, with (normally) one copy per processor core on your computer. One of these copies is known as the master copy, and is the one that is used to control all of the worker copies. Because of this, Python code has to be written into a text file and executed using the Python interpreter. It is not recommended to try to run a parallel Python script interactively, e.g. via IPython, the Python Console or Jupyter notebooks.\nIn addition, because it achieves parallelism by running multiple copies of your script, it forces you to write it in a particular way. All imports should be at the top of the script, followed by all function and class definitions. This is to ensure that all copies of the script have access to the same modules, functions and classes. Then, you should ensure that only the master copy of the script runs the code by protecting it behind an if __name__ == \"__main__\" statement.\nAn example (non-functional) script is shown below:\n# all imports should be at the top of your script\nimport concurrent.futures\nimport os\nimport sys\n\n# all function and class definitions must be next\ndef add(x, y):\n    \"\"\"Function to return the sum of the two arguments\"\"\"\n    return x + y\n\ndef product(x, y):\n    \"\"\"Function to return the product of the two arguments\"\"\"\n    return x * y\n\nif __name__ == \"__main__\":\n    # You must now protect the code being run by\n    # the master copy of the script by placing it\n    # in this block\n\n    a = [1, 2, 3, 4, 5]\n    b = [6, 7, 8, 9, 10]\n\n    # Now write your parallel code...\n    etc. etc.",
    "crumbs": [
      "Multicore (local) Parallel Programming",
      "Parallel Python"
    ]
  },
  {
    "objectID": "pages/answer_shakespeare_countwords_async.html",
    "href": "pages/answer_shakespeare_countwords_async.html",
    "title": "Introducing Parallel Python",
    "section": "",
    "text": "%%writefile countwords.py\n\nimport re\nimport sys\n\nfrom functools import reduce\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef count_words(file):\n    \"\"\"\n    Count the number of times every word in `file` occurs.\n\n    Args:\n        file (Path): the file to count the words in\n\n    Returns:\n        dict: a mapping of word to count\n    \"\"\"\n\n    all_words = {}\n\n    text = file.read_text()\n    words = text.split()\n\n    for word in words:\n        #lowercase the word and remove all\n        #characters that are not [a-z] or hyphen\n        word = word.lower()\n        match = re.search(r\"([a-z\\-]+)\", word)\n\n        if match:\n            word = match.groups()[0]\n\n            if word in all_words:\n                all_words[word] += 1\n            else:\n                all_words[word] = 1\n\n    return all_words\n\n\ndef reduce_dicts(dict1, dict2):\n    \"\"\"\n    Combine (reduce) the passed two dictionaries to return\n    a dictionary that contains the keys of both, where the\n    values are equal to the sum of values for each key\n    \"\"\"\n\n    # explicitly copy the dictionary, as otherwise\n    # we risk modifying 'dict1'\n    combined = {}\n\n    for key in dict1:\n        combined[key] = dict1[key]\n\n    for key in dict2:\n        if key in combined:\n            combined[key] += dict2[key]\n        else:\n            combined[key] = dict2[key]\n\n    return combined\n\nif __name__ == \"__main__\":\n    files = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n    with ProcessPoolExecutor() as pool:\n        results = pool.map(count_words, files, chunksize=5)\n\n    words = reduce(reduce_dicts, results)\n\n    for key in sorted(words.keys()):\n        if words[key] &gt; 2000:\n            print(f\"{key} == {words[key]}\")\n\nOverwriting countwords.py\n\n\nWriting countwords.py\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\n\n\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nCell In[2], line 4\n      1 import urllib\n      2 import tarfile\n----&gt; 4 urllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\n      5 with tarfile.open(\"shakespeare.tar.bz2\") as tar:\n      6     tar.extractall()\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:240, in urlretrieve(url, filename, reporthook, data)\n    223 \"\"\"\n    224 Retrieve a URL into a temporary location on disk.\n    225 \n   (...)\n    236 data file as well as the resulting HTTPMessage object.\n    237 \"\"\"\n    238 url_type, path = _splittype(url)\n--&gt; 240 with contextlib.closing(urlopen(url, data)) as fp:\n    241     headers = fp.info()\n    243     # Just return the local path and the \"headers\" for file://\n    244     # URLs. No sense in performing a copy unless requested.\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:215, in urlopen(url, data, timeout, cafile, capath, cadefault, context)\n    213 else:\n    214     opener = _opener\n--&gt; 215 return opener.open(url, data, timeout)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:521, in OpenerDirector.open(self, fullurl, data, timeout)\n    519 for processor in self.process_response.get(protocol, []):\n    520     meth = getattr(processor, meth_name)\n--&gt; 521     response = meth(req, response)\n    523 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:630, in HTTPErrorProcessor.http_response(self, request, response)\n    627 # According to RFC 2616, \"2xx\" code indicates that the client's\n    628 # request was successfully received, understood, and accepted.\n    629 if not (200 &lt;= code &lt; 300):\n--&gt; 630     response = self.parent.error(\n    631         'http', request, response, code, msg, hdrs)\n    633 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:559, in OpenerDirector.error(self, proto, *args)\n    557 if http_err:\n    558     args = (dict, 'default', 'http_error_default') + orig_args\n--&gt; 559     return self._call_chain(*args)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:492, in OpenerDirector._call_chain(self, chain, kind, meth_name, *args)\n    490 for handler in handlers:\n    491     func = getattr(handler, meth_name)\n--&gt; 492     result = func(*args)\n    493     if result is not None:\n    494         return result\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:639, in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs)\n    638 def http_error_default(self, req, fp, code, msg, hdrs):\n--&gt; 639     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n\nHTTPError: HTTP Error 404: Not Found\n\n\n\npython -u countwords.py shakespeare\na == 10737\nall == 2687\nand == 17573\nare == 2530\nas == 4097\nbe == 4859\nbut == 4505\nby == 2584\ndo == 2944\nfor == 5395\ngood == 2075\nhave == 4425\nhe == 5005\nher == 3249\nhim == 3829\nhis == 4419\ni == 16856\nif == 2598\nin == 7624\nis == 6851\nit == 5894\nlord == 2071\nme == 5674\nmy == 8380\nno == 2784\nnot == 6323\no == 2316\nof == 11332\non == 2204\nshall == 2441\nshe == 2155\nsir == 2527\nso == 3574\nthat == 8006\nthe == 19443\nthee == 2196\nthis == 4627\nthou == 3719\nthy == 2465\nto == 13615\nwe == 2497\nwhat == 3608\nwill == 3634\nwith == 5280\nyou == 11108\nyour == 4832"
  },
  {
    "objectID": "pages/140-lambdas.html",
    "href": "pages/140-lambdas.html",
    "title": "Anonymous Functions (lambda)",
    "section": "",
    "text": "You have seen how functional programming allows you to write functions that can be used for mapping and reducing data. However, to date, this hasn’t saved you from typing much code. This is because you have had to declare every function that you want to use, i.e. you had to use syntax such as:\n\ndef add(x, y):\n    return x + y\n\nto both provide the code to the function (return x + y) and also to assign that function to an initial variable (add).\nAnonymous functions (also called lambdas) allow you to declare the code for functions without having to assign them to a variable. They are used for short, one-line functions, such as the add function used above:\n\na = [1, 2, 3, 4, 5]\nb = [6, 7, 8, 9, 10]\n\ntotal = map(lambda x, y: x + y, a, b)\n\nlist(total)\n\n[7, 9, 11, 13, 15]\n\n\nThis code has used lambda to create an anonymous function that is passed as an argument to map. The format of lambda is:\nlambda arguments: expression\nwhere arguments is a comma separated list of arguments to the function, and expression is a single line of code. Note that this function will automatically return the result of this single line of code.\nAnonymous lambda functions are just like any other function. The only difference is that they have been created without being initially assigned to a variable. The unnamed function object created using\nlambda arguments: expression\nis completely identical to\ndef name(arguments):\n    return expression\nexcept that the def version assigns this function object to a variable called name, while the lambda version creates the function object without assigning it to a variable.\nTo understand the example we had above, it takes two arguments, x and y:\n#      ↓  ↓\nlambda x, y: x + y\nand returns the result of the expression x + y.\nYou use lambda whenever you want to pass a simple, one-line expression as an argument:\n\nfrom functools import reduce\n\na = [1, 2, 3, 4, 5]\n\nreduce(lambda x, y: x * y, a)\n\n120\n\n\n\nsquares = map(lambda x: x * x, a)\n\nlist(squares)\n\n[1, 4, 9, 16, 25]\n\n\n\nBinding Arguments\nAs well as using lambda to create functions as arguments, you can also use lambda to more quickly create simple functions:\n\nsquare = lambda x: x * x\n\nsquare(5)\n\n25\n\n\nHere you have created a simple function that accepts one argument, and returns that argument squared. You have immediately assigned this function to the variable square, allowing you to call this function via this variable.\nWith lambda, you are limited to using this to create functions that have only a single expression (i.e. single line of code). However, this single expression can include a call to another function. This can allow you to quickly create specialised versions of more generic functions by binding their arguments:\n\ndef add(x, y):\n    \"\"\"Return the sum of the two arguments\"\"\"\n    return x + y\n\nplus_five = lambda x: add(x, 5)\n\nplus_five(7)\n\n12\n\n\nHere, we have created a new function that takes a single argument (x), and that only calls the function add with arguments x and 5. This is assigned to the variable plus_five. This means that plus_five is now a function that takes a single argument, and returns the result of adding five to that argument.\nIn this example, we have used lambda to bind the value of the second argument of add to the number 5. The use of lambda has reduced the amount of code needed to create the plus_five function. Compare this to what is needed if we didn’t use lambda:\n\ndef plus_five(x):\n    return add(x, 5)\n\nplus_five(7)\n\n12\n\n\nThe saving is more useful when we want to create specialised functions for mapping or reduction:\n\ndef multiply(x, y):\n    \"\"\"Return the product of the two arguments\"\"\"\n    return x * y\n\na = [1, 2, 3, 4, 5]\n\ndouble_a = map(lambda x: multiply(x, 2), a)\n\nlist(double_a)\n\n[2, 4, 6, 8, 10]\n\n\n\n\n\n\n\n\nExercise\n\n\n\nRewrite your countlines.py script so that it uses lambda instead of any defined function (e.g. you should replace the add function).\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n%%writefile countlines.py\n\nimport sys\nfrom functools import reduce\nfrom pathlib import Path\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\n# get all of the names of the plays from the command line\nfiles = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n# map the count_lines function against all of the\n# files listed in \"filenames\"\nplay_line_count = sorted(map(count_lines_in_file, files))\n\n# print out the filenames of the plays along with their line counts\nfor f, count in zip(files, play_line_count):\n    print(f\"{f} has {count} lines\")\n\ntotal = reduce(lambda x,y: x+y, play_line_count)\n\nprint(\"The total number of lines is %s.\" % total)\n\nOverwriting countlines.py\n\n\nOverwriting countlines.py\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\n\n\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nCell In[10], line 4\n      1 import urllib\n      2 import tarfile\n----&gt; 4 urllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\n      5 with tarfile.open(\"shakespeare.tar.bz2\") as tar:\n      6     tar.extractall()\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:240, in urlretrieve(url, filename, reporthook, data)\n    223 \"\"\"\n    224 Retrieve a URL into a temporary location on disk.\n    225 \n   (...)\n    236 data file as well as the resulting HTTPMessage object.\n    237 \"\"\"\n    238 url_type, path = _splittype(url)\n--&gt; 240 with contextlib.closing(urlopen(url, data)) as fp:\n    241     headers = fp.info()\n    243     # Just return the local path and the \"headers\" for file://\n    244     # URLs. No sense in performing a copy unless requested.\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:215, in urlopen(url, data, timeout, cafile, capath, cadefault, context)\n    213 else:\n    214     opener = _opener\n--&gt; 215 return opener.open(url, data, timeout)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:521, in OpenerDirector.open(self, fullurl, data, timeout)\n    519 for processor in self.process_response.get(protocol, []):\n    520     meth = getattr(processor, meth_name)\n--&gt; 521     response = meth(req, response)\n    523 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:630, in HTTPErrorProcessor.http_response(self, request, response)\n    627 # According to RFC 2616, \"2xx\" code indicates that the client's\n    628 # request was successfully received, understood, and accepted.\n    629 if not (200 &lt;= code &lt; 300):\n--&gt; 630     response = self.parent.error(\n    631         'http', request, response, code, msg, hdrs)\n    633 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:559, in OpenerDirector.error(self, proto, *args)\n    557 if http_err:\n    558     args = (dict, 'default', 'http_error_default') + orig_args\n--&gt; 559     return self._call_chain(*args)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:492, in OpenerDirector._call_chain(self, chain, kind, meth_name, *args)\n    490 for handler in handlers:\n    491     func = getattr(handler, meth_name)\n--&gt; 492     result = func(*args)\n    493     if result is not None:\n    494         return result\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:639, in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs)\n    638 def http_error_default(self, req, fp, code, msg, hdrs):\n--&gt; 639     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n\nHTTPError: HTTP Error 404: Not Found\n\n\n\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 2938 lines\nshakespeare/antonyandcleopatra has 3116 lines\nshakespeare/asyoulikeit has 3400 lines\nshakespeare/comedyoferrors has 3606 lines\nshakespeare/coriolanus has 3768 lines\nshakespeare/cymbeline has 3872 lines\nshakespeare/hamlet has 3877 lines\nshakespeare/juliuscaesar has 3884 lines\nshakespeare/kinglear has 3974 lines\nshakespeare/loveslabourslost has 4018 lines\nshakespeare/macbeth has 4064 lines\nshakespeare/measureforemeasure has 4108 lines\nshakespeare/merchantofvenice has 4123 lines\nshakespeare/merrywivesofwindsor has 4149 lines\nshakespeare/midsummersnightsdream has 4336 lines\nshakespeare/muchadoaboutnothing has 4338 lines\nshakespeare/othello has 4449 lines\nshakespeare/periclesprinceoftyre has 4516 lines\nshakespeare/romeoandjuliet has 4644 lines\nshakespeare/tamingoftheshrew has 4767 lines\nshakespeare/tempest has 5425 lines\nshakespeare/timonofathens has 5444 lines\nshakespeare/titusandronicus has 5486 lines\nshakespeare/troilusandcressida has 5526 lines\nshakespeare/twelfthnight has 5837 lines\nshakespeare/twogentlemenofverona has 5999 lines\nshakespeare/winterstale has 6046 lines\nThe total number of lines is 119713.",
    "crumbs": [
      "Functional Programming",
      "Anonymous Functions (lambda)"
    ]
  },
  {
    "objectID": "pages/240-futures.html",
    "href": "pages/240-futures.html",
    "title": "Asynchronous Functions and Futures",
    "section": "",
    "text": "The ProcessPoolExecutor.map function allows you to map a single function across an entire list of data. But what if you want to apply lots of different functions? The solution is to tell individual workers to run different functions, by submitting functions to workers.\nThe ProcessPoolExecutor class comes with the function submit. This is used to tell one process in the worker pool to run a specified function. For example, create a new script called pool_submit.py and type into it:\n\n\npool_submit.py\n\nimport os\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef slow_function(nsecs):\n    \"\"\"\n    Function that sleeps for 'nsecs' seconds, returning\n    the number of seconds that it slept\n    \"\"\"\n\n    print(f\"Process {os.getpid()} going to sleep for {nsecs} second(s)\")\n\n    # use the time.sleep function to sleep for nsecs seconds\n    time.sleep(nsecs)\n\n    print(f\"Process {os.getpid()} waking up\")\n\n    return nsecs\n\nif __name__ == \"__main__\":\n    print(f\"Master process is PID {os.getpid()}\")\n\n    with ProcessPoolExecutor() as pool:\n        r = pool.submit(slow_function, 5)\n\n    print(f\"Result is {r.result()}\")\n\nRun this script:\npython pool_submit.py\nMaster process is PID 28612\nProcess 28613 going to sleep for 5 second(s)\nProcess 28613 waking up\nResult is 5\nYou should see the something like this printed to the screen (with a delay of five seconds when the worker process sleeps).\nThe key line in this script is:\nr = pool.submit(slow_function, 5)\nThe pool.submit function will request that one of the workers in the pool should run the passed function (in this case slow_function), with the arguments passed to the submit. The value returned by pool.submit is a special kind of object and in order to get the return valule of the function call out of it, we have to call the result() method on it. The reasons for this will be covered shortly.\nThe call to submit can take multiple arguments, as long as the submitted function takes the same number of arguments. For example, edit your pool_submit.py function to read:\n\n\npool_submit.py\n\nimport os\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef slow_add(nsecs, x, y):\n    \"\"\"\n    Function that sleeps for 'nsecs' seconds, and\n    then returns the sum of x and y\n    \"\"\"\n    print(f\"Process {os.getpid()} going to sleep for {nsecs} second(s)\")\n\n    time.sleep(nsecs)\n\n    print(f\"Process {os.getpid()} waking up\")\n\n    return x + y\n\nif __name__ == \"__main__\":\n    print(f\"Master process is PID {os.getpid()}\")\n\n    with ProcessPoolExecutor() as pool:\n        r = pool.submit(slow_add, 1, 6, 7)\n\n    print(f\"Result is {r.result()}\")\n\nHere we have edited slow_function to be slow_add, with this function accepting three arguments. These three arguments are passed using the arguments in pool.apply(slow_add, 1, 6, 7).\nRunning this script using should give output similar to:\npython pool_submit.py\nMaster process is PID 28633\nProcess 28634 going to sleep for 1 second(s)\nProcess 28634 waking up\nResult is 13\n\nAsynchronous Functions\nThe reason for the explicit call to r.result() is that it allows us to submit multiple functions to run in parallel and to then request their results once they have finished:\n\n\npool_submit.py\n\nimport os\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef slow_add(nsecs, x, y):\n    \"\"\"\n    Function that sleeps for 'nsecs' seconds, and\n    then returns the sum of x and y\n    \"\"\"\n    print(f\"Process {os.getpid()} going to sleep for {nsecs} second(s)\")\n\n    time.sleep(nsecs)\n\n    print(f\"Process {os.getpid()} waking up\")\n\n    return x + y\n\nif __name__ == \"__main__\":\n    print(f\"Master process is PID {os.getpid()}\")\n\n    with ProcessPoolExecutor() as pool:\n        r1 = pool.submit(slow_add, 1, 6, 7)\n        r2 = pool.submit(slow_add, 1, 2, 3)\n\n        print(f\"Result one is {r1.result()}\")\n        print(f\"Result two is {r2.result()}\")\n\nRunning this script using should give output similar to:\npython applyasync.py\nMaster process is PID 28667\nProcess 28668 going to sleep for 1 second(s)\nProcess 28669 going to sleep for 1 second(s)\nProcess 28669 waking up\nProcess 28668 waking up\nResult one is 13\nResult two is 5\nThe keys lines of this script are\nr1 = pool.submit(slow_add, 1, 6, 7)\nr2 = pool.submit(slow_add, 1, 2, 3)\nThe key thing to notice here is that while the first call to submit is submitting a function which takes a second to run, Python is not waiting for that function to finish before moving on to the second submit call. They will both be submitted at almost the same time. It’s not until the call to r1.result() that the program will wait for the slow_add function to finish.\nMost noticeably here, even though each function call took one second to run, the whole program did not take two seconds. Due to running them in parallel, it finished the whole program in just over one second.\n\n\nFutures\nAn issue with running a function asynchronously is that the return value of the function is not available immediately. This means that, when running an asynchronous function, you don’t get the return value directly. Instead, submit returns a placeholder for the return value. This placeholder is called a “future”, and is a variable that in the future will contain the result of the function.\nFutures are a very common variable type in parallel programming across many languages. Futures provide several common functions: - Block (wait) until the result is available. In concurrent.futures, this is done implicitly via the .result() function, e.g. r1.result() in the above script. There is also an implict wait when then context manager (the with block) closes to make sure all running process are finished. - Retrieve the result when it is available (blocking until it is available). This is also done with the .result() function, e.g. r1.result(). - Test whether or not the result is available. This is the .done() function, which returns True when the asynchronous function has finished and the result is available via .result(). - Test whether or not the function was a success, e.g. whether or not an exception was raised when running the function. This is the .exception() function, which returns the None if the asynchronous function completed without raising an exception and return the exception object if there was an error.\nIn the above example, r1 and r2 were both futures for the results of the two asynchronous calls of slow_sum. The two slow_sum calls were processed by two worker processes. The master process was then blocked using r1.result() to wait for the result of the first call, and then blocked using r2.result() to wait for the result of the second call.\nWe can explore this more using the following example. Create a script called future.py and copy into it:\n\n\nfuture.py\n\n\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef slow_add(nsecs, x, y):\n    \"\"\"\n    Function that sleeps for 'nsecs' seconds, and\n    then returns the sum of x and y\n    \"\"\"\n    time.sleep(nsecs)\n    return x + y\n\ndef slow_diff(nsecs, x, y):\n    \"\"\"\n    Function that sleeps for 'nsecs' seconds, and\n    then retruns the difference of x and y\n    \"\"\"\n    time.sleep(nsecs)\n    return x - y\n\ndef broken_function(nsecs):\n    \"\"\"Function that deliberately raises an AssertationError\"\"\"\n    time.sleep(nsecs)\n    raise ValueError(\"Called broken function\")\n\nif __name__ == \"__main__\":\n    futures = []\n\n    with ProcessPoolExecutor() as pool:\n        futures.append(pool.submit(slow_add, 3.1, 6, 7))\n        futures.append(pool.submit(slow_diff, 2.1, 5, 2))\n        futures.append(pool.submit(slow_add, 1.1, 8, 1))\n        futures.append(pool.submit(slow_diff, 5.1, 9, 2))\n        futures.append(pool.submit(broken_function, 4.1))\n\n        while True:\n            all_finished = True\n\n            print(\"\\nHave the workers finished?\")\n\n            for i, future in enumerate(futures):\n                if future.done():\n                    print(f\"Task {i} has finished\")\n                else:\n                    all_finished = False\n                    print(f\"Task {i} is running...\")\n\n            if all_finished:\n                break\n\n            time.sleep(1)\n\n        print(\"\\nHere are the results.\")\n\n        for i, future in enumerate(futures):\n            if future.exception() is None:\n                print(f\"Task {i} was successful. Result is {future.result()}\")\n            else:\n                print(f\"Task {i} failed!\")\n                e = future.exception()\n                print(f\"    Error = {type(e)} : {e}\")\n\nRunning this script using should give output similar to:\npython future.py\nHave the workers finished?\nTask 0 is running...\nTask 1 is running...\nTask 2 is running...\nTask 3 is running...\nTask 4 is running...\n\nHave the workers finished?\nTask 0 is running...\nTask 1 is running...\nTask 2 is running...\nTask 3 is running...\nTask 4 is running...\n\nHave the workers finished?\nTask 0 is running...\nTask 1 is running...\nTask 2 has finished\nTask 3 is running...\nTask 4 is running...\n\nHave the workers finished?\nTask 0 is running...\nTask 1 has finished\nTask 2 has finished\nTask 3 is running...\nTask 4 is running...\n\nHave the workers finished?\nTask 0 has finished\nTask 1 has finished\nTask 2 has finished\nTask 3 is running...\nTask 4 is running...\n\nHave the workers finished?\nTask 0 has finished\nTask 1 has finished\nTask 2 has finished\nTask 3 is running...\nTask 4 is running...\n\nHave the workers finished?\nTask 0 has finished\nTask 1 has finished\nTask 2 has finished\nTask 3 has finished\nTask 4 has finished\n\nHere are the results.\nTask 0 was successful. Result is 13\nTask 1 was successful. Result is 3\nTask 2 was successful. Result is 9\nTask 3 was successful. Result is 7\nTask 4 failed!\n    Error = &lt;class 'ValueError'&gt; : Called broken function\nIs this output that you expected? Note that the exception raised by broken_function is held safely in its associated future. This is indicated by .exception() not returning None (if you .result() a future that contains an exception, then that exception is raised).\n\n\n\n\n\n\nExercise\n\n\n\nEdit the future.py script so that you can control the number of workers in the pool using a command line argument (e.g. using ProcessPoolExecutor(max_workers=int(sys.argv[1])) rather than ProcessPoolExecutor()).\nEdit the script to add calls to more asynchronous functions.\nThen experiment with running the script with different numbers of processes in the pool and with different numbers of asynchronous function calls.\nHow are the asynchronous function calls distributed across the pool of worker processes?",
    "crumbs": [
      "Multicore (local) Parallel Programming",
      "Asynchronous Functions and Futures"
    ]
  },
  {
    "objectID": "pages/130-reduce.html",
    "href": "pages/130-reduce.html",
    "title": "Reduction",
    "section": "",
    "text": "We have seen how to map a function across a list of data, with the return value of each function call placed into a list of results. For example, you summed together two lists of numbers using map using code such as this. In the Python Console type:\n\ndef add(x, y):\n    \"\"\"Function to return the sum of x and y\"\"\"\n    return x + y\n\na = [1, 2, 3, 4, 5]\nb = [6, 7, 8, 9, 10]\n\nresult = map(add, a, b)\n\nlist(result)\n\n[7, 9, 11, 13, 15]\n\n\nThis returns a list of results. However, what if we want to sum every value in the returned list of results to form a single value? We could write the code by hand, e.g.:\n\ntotal = 0\n\nresult = map(add, a, b)\n\nfor i in result:\n    total += i\n\nprint(\"Total = %s\" % total)\n\nTotal = 55\n\n\nThis process of summing a list of numbers into a total is an example of “reduction”. The list of numbers has been reduced to a total by adding each value onto a running total. While mapping takes N elements and creates N new elements, a reduction takes N elements and returns 1 element. Reduction is the complement to mapping, and as such, Python has a reduce function.\nThe reduce function is available from the standard functools module:\n\nfrom functools import reduce\n\nresult = map(add, a, b)\n\nreduce(add, result)\n\n55\n\n\nreduce takes two required arguments and one additional, optional argument:\n\nThe reduction function used to reduce a pair of arguments to a single result, e.g. add takes two arguments and returns the sum of those arguments. This can be any function that accepts two arguments and returns a single result.\nThe list of values to be reduced.\nAn (optional) initial value that is used as the first value for the reduction.\n\nFor example, type\n\na = [1, 2, 3, 4, 5]\n\nreduce(add, a, 10)\n\n25\n\n\nWhy do you think the answer is 25?\nPython’s reduce applies the reduction function (in this case add) cumulatively from left to right along the items of a list. If an initial value is supplied then this is used as the first value. Otherwise, the first value is the result of the reduction function applied to the first two items in the list. In the above case, reduce performed:\n\ntotal = 10\ntotal = add(total, 1)\ntotal = add(total, 2)\ntotal = add(total, 3)\ntotal = add(total, 4)\ntotal = add(total, 5)\n\nThe result is thus 25, i.e. (((((10+1)+2)+3)+4)+5).\nThe reduction function can be any function that accepts two arguments and returns a single value. For example, let’s now use reduce to calculate the product of all of the values in the list. To do this, we need to create a new function that will take in two arguments and return their product:\n\ndef multiply(x, y):\n    \"\"\"Return the product of the two arguments\"\"\"\n    return x * y\n\nreduce(multiply, a)\n\n120\n\n\nYou should see that the product is 120. Is this what you expected? In this case, reduce performed; 1. total = multiply(1, 2) 2. total = multiply(total, 3) 3. total = multiply(total, 4) 4. total = multiply(total, 5)\ni.e. it set total equal to \\(((((1×2)×3)×4)×5) = 120\\).\nNote that the reduction function is not limited to just numbers. You can write a reduction function to reduce any types of object together. For example, we could use reduce to join together some strings:\n\ndef join_strings(x, y):\n    return f\"{x} {y}\"\n\na = [\"cat\", \"dog\", \"mouse\", \"fish\"]\n\nreduce(join_strings, a)\n\n'cat dog mouse fish'\n\n\n\n\n\n\n\n\nExercise\n\n\n\nModify your countlines.py script so that, in addition to printing out the total number of lines in each Shakespeare play, it also uses reduce to print out the total number of lines in all Shakespeare plays.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n%%writefile countlines.py\n\nimport sys\nfrom functools import reduce\nfrom pathlib import Path\n\ndef count_lines_in_file(file):\n    \"\"\"\n    Calculate the number of lines of text in a single file\n    \"\"\"\n    text = file.read_text()\n    lines = text.split(\"\\n\")\n    return len(lines)\n\n# get all of the names of the plays from the command line\nfiles = sorted(Path(\"shakespeare\").glob(\"*\"))\n\n# map the count_lines function against all of the\n# files listed in \"filenames\"\nplay_line_count = list(map(count_lines_in_file, files))\n\n# print out the filenames of the plays along with their line counts\nfor f, count in zip(files, play_line_count):\n    print(f\"{f} has {count} lines\")\n\n\n### This is the new bit of the code\n\ndef add(x, y):\n    \"\"\"Return the sum of the two arguments\"\"\"\n    return x + y\n\ntotal = reduce(add, play_line_count)\n\nprint(\"The total number of lines is %s.\" % total)\n\nOverwriting countlines.py\n\n\nOverwriting countlines.py\n\nimport urllib\nimport tarfile\n\nurllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\nwith tarfile.open(\"shakespeare.tar.bz2\") as tar:\n    tar.extractall()\n\n\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nCell In[8], line 4\n      1 import urllib\n      2 import tarfile\n----&gt; 4 urllib.request.urlretrieve(\"https://github.com/uob-training/introducing-parallel-python/data/shakespeare.tar.bz2\", \"shakespeare.tar.bz2\")\n      5 with tarfile.open(\"shakespeare.tar.bz2\") as tar:\n      6     tar.extractall()\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:240, in urlretrieve(url, filename, reporthook, data)\n    223 \"\"\"\n    224 Retrieve a URL into a temporary location on disk.\n    225 \n   (...)\n    236 data file as well as the resulting HTTPMessage object.\n    237 \"\"\"\n    238 url_type, path = _splittype(url)\n--&gt; 240 with contextlib.closing(urlopen(url, data)) as fp:\n    241     headers = fp.info()\n    243     # Just return the local path and the \"headers\" for file://\n    244     # URLs. No sense in performing a copy unless requested.\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:215, in urlopen(url, data, timeout, cafile, capath, cadefault, context)\n    213 else:\n    214     opener = _opener\n--&gt; 215 return opener.open(url, data, timeout)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:521, in OpenerDirector.open(self, fullurl, data, timeout)\n    519 for processor in self.process_response.get(protocol, []):\n    520     meth = getattr(processor, meth_name)\n--&gt; 521     response = meth(req, response)\n    523 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:630, in HTTPErrorProcessor.http_response(self, request, response)\n    627 # According to RFC 2616, \"2xx\" code indicates that the client's\n    628 # request was successfully received, understood, and accepted.\n    629 if not (200 &lt;= code &lt; 300):\n--&gt; 630     response = self.parent.error(\n    631         'http', request, response, code, msg, hdrs)\n    633 return response\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:559, in OpenerDirector.error(self, proto, *args)\n    557 if http_err:\n    558     args = (dict, 'default', 'http_error_default') + orig_args\n--&gt; 559     return self._call_chain(*args)\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:492, in OpenerDirector._call_chain(self, chain, kind, meth_name, *args)\n    490 for handler in handlers:\n    491     func = getattr(handler, meth_name)\n--&gt; 492     result = func(*args)\n    493     if result is not None:\n    494         return result\n\nFile /opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:639, in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs)\n    638 def http_error_default(self, req, fp, code, msg, hdrs):\n--&gt; 639     raise HTTPError(req.full_url, code, msg, hdrs, fp)\n\nHTTPError: HTTP Error 404: Not Found\n\n\n\npython countlines.py shakespeare\nshakespeare/README has 3 lines\nshakespeare/allswellthatendswell has 4516 lines\nshakespeare/antonyandcleopatra has 5999 lines\nshakespeare/asyoulikeit has 4123 lines\nshakespeare/comedyoferrors has 2938 lines\nshakespeare/coriolanus has 5837 lines\nshakespeare/cymbeline has 5486 lines\nshakespeare/hamlet has 6046 lines\nshakespeare/juliuscaesar has 4108 lines\nshakespeare/kinglear has 5526 lines\nshakespeare/loveslabourslost has 4336 lines\nshakespeare/macbeth has 3877 lines\nshakespeare/measureforemeasure has 4338 lines\nshakespeare/merchantofvenice has 3884 lines\nshakespeare/merrywivesofwindsor has 4449 lines\nshakespeare/midsummersnightsdream has 3116 lines\nshakespeare/muchadoaboutnothing has 4064 lines\nshakespeare/othello has 5425 lines\nshakespeare/periclesprinceoftyre has 3872 lines\nshakespeare/romeoandjuliet has 4767 lines\nshakespeare/tamingoftheshrew has 4149 lines\nshakespeare/tempest has 3400 lines\nshakespeare/timonofathens has 3974 lines\nshakespeare/titusandronicus has 3768 lines\nshakespeare/troilusandcressida has 5444 lines\nshakespeare/twelfthnight has 4018 lines\nshakespeare/twogentlemenofverona has 3606 lines\nshakespeare/winterstale has 4644 lines\nThe total number of lines is 119713.",
    "crumbs": [
      "Functional Programming",
      "Reduction"
    ]
  }
]